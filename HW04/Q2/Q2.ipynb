{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_EZ8enOORfQ_"
   },
   "source": [
    "# HW04 : Problem 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D9smU50W77n0"
   },
   "source": [
    "## Part O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m2ff2DWeUYRP",
    "outputId": "99436119-1889-4033-d25d-2f66ce9794f2"
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from visual_dataset import getGroundTruthList\n",
    "pprint(getGroundTruthList(17))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "56Sqzq7BRxI4",
    "outputId": "ee289539-f4b8-4d44-ef3e-f2b7792e4346"
   },
   "outputs": [],
   "source": [
    "from visual_dataset import visual_dataset\n",
    "visual_dataset(17, show_name=False, fontsize=20, figsize=(10,10))\n",
    "visual_dataset(17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JCc6yNFg8H5M"
   },
   "source": [
    "## Part I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "hpC9TDQWav3p",
    "outputId": "8cfcb450-8bb6-4cd4-d0e5-d6fc12a32d92"
   },
   "outputs": [],
   "source": [
    "from prepare_data import prepare_data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "number = 17\n",
    "cropped_images, classes = prepare_data(number)\n",
    "\n",
    "fig = plt.figure(figsize=(15,8))\n",
    "fig.subplots_adjust(hspace=0.5)\n",
    "for i in range(20):\n",
    "  plt.subplot(4,5,i+1)\n",
    "  plt.imshow(cropped_images[i])\n",
    "  plt.grid(False); plt.xticks([]); plt.yticks([])\n",
    "  plt.title(classes[i].name, fontdict={'color':'black', 'fontsize':16})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j01f23L1hwMI",
    "outputId": "eb85726e-5e13-43d1-b5a0-2cdf153fe992"
   },
   "outputs": [],
   "source": [
    "categories = [cat.value for cat in classes]\n",
    "categories "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-U-xnrvf8Q22"
   },
   "source": [
    "## Part II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "w6UT5P9kcNZV",
    "outputId": "bc4af511-112f-4e57-e345-dbe3eadabdda"
   },
   "outputs": [],
   "source": [
    "from transform import resize_image\n",
    "\n",
    "img = cropped_images[0]\n",
    "plt.imshow(resize_image(img, (224,224)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "id": "ptGYg0UE3XNQ",
    "outputId": "7c1980ae-1867-4b04-c25c-99a1524baadf"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from prepare_data import getGroundTruthList, ObjectType\n",
    "from prepare_data import get_number_of_files\n",
    "\n",
    "\n",
    "number_of_labeled_files, number_of_nonlabeled_files = get_number_of_files()\n",
    "\n",
    "all_classes = np.array([]);\n",
    "for i in range(1,number_of_labeled_files):\n",
    "  groundTruthList = getGroundTruthList(i)\n",
    "  classes_i = np.array([obj.object_type.value for obj in groundTruthList])\n",
    "  all_classes = np.concatenate((all_classes, classes_i), axis=0)\n",
    "all_classes = np.concatenate((all_classes, np.zeros(number_of_nonlabeled_files)), axis=0)\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "ax = plt.subplot(111)\n",
    "ax.hist(all_classes, bins=np.arange(0,12), rwidth=0.75, edgecolor='black')\n",
    "ax.set_xticks(.5+np.arange(11))\n",
    "ax.set_xlim(0,11)\n",
    "ax.set_xticklabels([ObjectType(i).name for i in range(11)])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "counts, bins = np.histogram(all_classes,bins=np.arange(-0.5,11.5), density=False)\n",
    "P_removal = (counts - counts.min()) / counts\n",
    "\n",
    "np.savez_compressed('unbalanced-info.npz', counts=counts, bins=bins, P_removal=P_removal, num_positive=number_of_labeled_files, num_negative=number_of_nonlabeled_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2QJAJj8nYsC9"
   },
   "source": [
    "> make it balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 338
    },
    "id": "uJ8GPiJatzLf",
    "outputId": "cccd827c-bc80-4166-eefb-cc681b7cc4f3"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm \n",
    "from prepare_data import getGroundTruthList, ObjectType\n",
    "from prepare_data import load_negative, load_positive, prepare_data\n",
    "\n",
    "np.random.seed(0)\n",
    "target_size = (224, 224)\n",
    "\n",
    "all_classes = np.array([],dtype=np.uint8);\n",
    "all_images = np.zeros((0,*target_size,3));\n",
    "for i in tqdm(range(1,number_of_labeled_files), desc=\"Loading…\",  ascii=False, ncols=75): \n",
    "    images_i, classes_i = prepare_data(i)\n",
    "    classes_i = np.array([cat.value for cat in classes_i])\n",
    "    index_to_remove = np.where(P_removal[classes_i] > np.random.uniform(size=classes_i.shape))[0]\n",
    "    len_i = classes_i.shape[0];\n",
    "    classes_i = np.array([classes_i[k] for k in range(len_i) if k not in index_to_remove])\n",
    "    if classes_i.shape[0] == 0: continue\n",
    "    images_i = np.array([resize_image(images_i[k],target_size) for k in range(len_i) if k not in index_to_remove])\n",
    "     \n",
    "    all_images = np.concatenate((all_images, images_i), axis=0).astype(np.uint8)\n",
    "    all_classes = np.concatenate((all_classes, classes_i), axis=0)\n",
    "\n",
    "classes_i = np.zeros(number_of_nonlabeled_files, dtype=np.int64)\n",
    "images_i = [load_negative(i+1) for i in range(number_of_nonlabeled_files)]\n",
    "len_i = classes_i.shape[0]\n",
    "index_to_remove = np.where(P_removal[classes_i] > np.random.uniform(size=classes_i.shape))[0]\n",
    "classes_i = np.array([classes_i[k] for k in range(len_i) if k not in index_to_remove])\n",
    "if classes_i.shape[0] > 0:\n",
    "  images_i = np.array([resize_image(images_i[k],target_size) for k in range(len_i) if k not in index_to_remove])\n",
    "  all_classes = np.concatenate((all_classes,classes_i), axis=0)\n",
    "  all_images = np.concatenate((all_images, images_i), axis=0).astype(np.uint8)\n",
    "\n",
    "np.savez_compressed('all_images.npz', all_images)\n",
    "np.savez_compressed('all_classes.npz', all_classes)\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "ax = plt.subplot(111)\n",
    "ax.hist(all_classes, bins=np.arange(0,12), rwidth=0.75, edgecolor='black')\n",
    "ax.set_xticks(.5+np.arange(11))\n",
    "ax.set_xlim(0,11)\n",
    "ax.set_xticklabels([ObjectType(i).name for i in range(11)])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0WjNTEp_86iu"
   },
   "source": [
    "## Part III"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LrmK8Pv7vozX"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "all_categories = to_categorical(all_classes)\n",
    "all_image_data = all_images.astype(np.float)/255.\n",
    "x_train, x_test, y_train, y_test = train_test_split(all_image_data, all_categories, test_size = 0.2, shuffle=True) \n",
    "x_subtrain, x_valid, y_subtrain, y_valid = train_test_split(x_train, y_train, test_size = 0.2, shuffle=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R96JPlDQ845L",
    "outputId": "9548f8e2-0c2d-46d9-c2d1-042ceac2d332"
   },
   "outputs": [],
   "source": [
    "# from tesorflow.keras.applications.vgg16 import VGG16\n",
    "# from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.layers import Dense\n",
    "# load the model\n",
    "pre_model = DenseNet121(weights='imagenet')\n",
    "# Freeze all the layers\n",
    "for layer in pre_model.layers[:]:\n",
    "    layer.trainable = False\n",
    "\n",
    "output = Dense(11,  activation='sigmoid', name='output')(pre_model.layers[-2].output)\n",
    "pre_model = Model(inputs=pre_model.inputs, outputs=output)\n",
    "pre_model.summary()\n",
    "# plot_model(pre_model, show_shapes=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o2hpf--Vb4CL",
    "outputId": "5d3a7ba2-615d-49da-9127-3664e17cf316"
   },
   "outputs": [],
   "source": [
    "pre_model.compile(optimizer='adam', loss=BinaryCrossentropy(), metrics=['accuracy'])\n",
    "history = pre_model.fit(x_subtrain,\n",
    "                    y_subtrain,\n",
    "                    epochs=20,\n",
    "                    verbose=2,\n",
    "                    validation_data=(x_valid, y_valid),\n",
    "                    batch_size=16\n",
    "                    )\n",
    "\n",
    "# save model and architecture to single file\n",
    "pre_model.save(\"pre_train.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xk_GZq-ZWpkQ",
    "outputId": "c851ac30-6810-48f3-dcd6-e43dc89c6843"
   },
   "outputs": [],
   "source": [
    "score, acc = pre_model.evaluate(x_test, y_test, batch_size=16)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rW73jjXzX5TY",
    "outputId": "1624f5de-0f53-4de7-ada4-6c28ccd0f175"
   },
   "outputs": [],
   "source": [
    "yhat = pre_model.predict(x_test, batch_size=16)\n",
    "yhat = yhat.argmax(axis=1) \n",
    "acc = np.sum(yhat==y_test.argmax(axis=1))/yhat.shape[0]\n",
    "print('Real Test Accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QEYuKdxhNOMi"
   },
   "source": [
    "## Part IV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UADrnLRJRPLi"
   },
   "source": [
    "### To test how it works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H3MUn2cZJfr8"
   },
   "source": [
    "> Create sample dataset to see what is happend in DataAugmentaion process "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 421
    },
    "id": "0YvsdOHl0XQ8",
    "outputId": "217e643d-1e67-4381-c5c6-b5d9627ae00e"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import requests\n",
    "from transform import resize_image\n",
    "\n",
    "url = 'https://github.com/dufourpascal/stepupai/raw/master/tutorials/data_augmentation/image.jpg'\n",
    "r = requests.get(url, allow_redirects=True)\n",
    "open('image.jpg', 'wb').write(r.content)\n",
    "url = 'https://github.com/dufourpascal/stepupai/raw/master/tutorials/data_augmentation/image_town.jpg'\n",
    "r = requests.get(url, allow_redirects=True)\n",
    "open('image_town.jpg', 'wb').write(r.content)\n",
    "\n",
    "size=(800,450)\n",
    "\n",
    "image = load_img('image.jpg')\n",
    "image = img_to_array(image).astype(np.uint8)\n",
    "data1 = np.expand_dims(resize_image(image,size), 0).astype(int)\n",
    "plt.axis('off')\n",
    "plt.imshow(data1[0])\n",
    "plt.show()\n",
    "\n",
    "image_town = load_img('image_town.jpg')\n",
    "image_town = img_to_array(image_town).astype(np.uint8)\n",
    "data2 = np.expand_dims(resize_image(image_town,size), 0).astype(int)\n",
    "plt.axis('off')\n",
    "plt.imshow(data2[0])\n",
    "plt.show()\n",
    "data=np.concatenate((data1,data2),axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4TXHbrLu4eCG"
   },
   "source": [
    "> without changes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "id": "npJL2FxFtBK-",
    "outputId": "f502e8cf-3f68-446e-ea9e-1d1bcefc42fb"
   },
   "outputs": [],
   "source": [
    "from transform import DataAugmentation\n",
    "datagen = DataAugmentation(data)\n",
    "datagen.plot(n_images=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sS2n1msz4nhu"
   },
   "source": [
    "> Width and Height Shift:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "id": "c7aF5iCc1ijt",
    "outputId": "7817e105-c332-4aa0-f2af-9e7794eaf265"
   },
   "outputs": [],
   "source": [
    "datagen = DataAugmentation(data)\n",
    "datagen.width_shift_range = 0.2\n",
    "datagen.height_shift_range = 0.2\n",
    "datagen.plot(n_images=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oJjYLaFb4vzp"
   },
   "source": [
    "> Image Flips:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "id": "MzmtWidJ1xz3",
    "outputId": "1f757af4-79a7-4ca7-bab0-8238cbb38352"
   },
   "outputs": [],
   "source": [
    "datagen = DataAugmentation(data)\n",
    "datagen.horizontal_flip = True\n",
    "datagen.vertical_flip = True\n",
    "datagen.plot(n_images=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZRvRRhZ344z4"
   },
   "source": [
    "> Rotation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "id": "nidyNl6S2HL8",
    "outputId": "38af40e9-a395-4aaf-c2a4-404fef2ae4fb"
   },
   "outputs": [],
   "source": [
    "datagen = DataAugmentation(data)\n",
    "datagen.shear_range = 20\n",
    "datagen.plot(n_images=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1yJ3FrN75ARL"
   },
   "source": [
    "> Zoom:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "id": "gPZmjQtA2MV_",
    "outputId": "24369a0a-2271-4763-ac4e-1cc962cef631"
   },
   "outputs": [],
   "source": [
    "datagen = DataAugmentation(data)\n",
    "datagen.zoom_range = [0.5, 1.5]\n",
    "datagen.plot(n_images=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aZGaOSFY5GiG"
   },
   "source": [
    "> Shear:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "id": "StcVUKsc2Myi",
    "outputId": "5f889ae4-53e4-497c-b90a-4673fd5bbc24"
   },
   "outputs": [],
   "source": [
    "datagen = DataAugmentation(data)\n",
    "datagen.shear_range = 20\n",
    "datagen.plot(n_images=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PwCGJA4F5PN5"
   },
   "source": [
    "> Brightness:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "id": "sQJQd-E52NTh",
    "outputId": "1b49ede5-383e-46b9-bb8f-cd03893922d3"
   },
   "outputs": [],
   "source": [
    "datagen = DataAugmentation(data)\n",
    "datagen.brightness_range = [0.5, 2.0]\n",
    "datagen.plot(n_images=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T2WXFCLR5n8u"
   },
   "source": [
    "> Combining Multiple Transformations for Data Augmentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "id": "40Aao2Tf5kv7",
    "outputId": "29982fe9-4ff0-4960-b564-306cf1b00eab"
   },
   "outputs": [],
   "source": [
    "datagen = DataAugmentation(data,\n",
    "              progressbar = True,\n",
    "              fill_mode='nearest',\n",
    "\t\t\t\t\t\t\thorizontal_flip=True,\n",
    "\t\t\t\t\t\t\twidth_shift_range=0.2,\n",
    "\t\t\t\t\t\t\theight_shift_range=0.2,\n",
    "\t\t\t\t\t\t\tzoom_range=[0.8, 1.2],\n",
    "\t\t\t\t\t\t\trotation_range=20,\n",
    "\t\t\t\t\t\t\tshear_range=10,\n",
    "\t\t\t\t\t\t\tbrightness_range = [0.75, 1.5])\n",
    "datagen.plot(n_images=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gZsmrhZ2Rdz1"
   },
   "source": [
    "### Use it and make dataset balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "03nofZr7Tqtq",
    "outputId": "4d662a7b-d70d-4335-8ebe-05b66b32cfb8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "from prepare_data import getGroundTruthList, ObjectType\n",
    "from prepare_data import prepare_data, load_negative\n",
    "from transform import resize_image\n",
    "\n",
    "info = np.load('unbalanced-info.npz') #list(info.keys())\n",
    "counts, bins, P_removal, num_positive, num_negative = info['counts'], info['bins'], info['P_removal'], info['num_positive'], info['num_negative']\n",
    "\n",
    "np.random.seed(0)\n",
    "target_size = (224, 224)\n",
    "\n",
    "all_classes = np.array([],dtype=np.uint8);\n",
    "all_images = np.zeros((0,*target_size,3));\n",
    "for i in tqdm(range(1, num_positive), desc=\"Loading…\",  ascii=False, ncols=75): \n",
    "    images_i, classes_i = prepare_data(i)\n",
    "    classes_i = np.array([cat.value for cat in classes_i]);    len_i = classes_i.shape[0];\n",
    "    images_i = np.array([resize_image(images_i[k],target_size) for k in range(len_i)])\n",
    "     \n",
    "    all_images = np.concatenate((all_images, images_i), axis=0).astype(np.uint8)\n",
    "    all_classes = np.concatenate((all_classes, classes_i), axis=0)\n",
    "\n",
    "classes_i = np.zeros(num_negative, dtype=np.int64)\n",
    "images_i = [load_negative(i+1) for i in range(num_negative)];      len_i = classes_i.shape[0]\n",
    "images_i = np.array([resize_image(images_i[k],target_size) for k in range(len_i)])\n",
    "all_classes = np.concatenate((all_classes,classes_i), axis=0)\n",
    "all_images = np.concatenate((all_images, images_i), axis=0).astype(np.uint8)\n",
    "\n",
    "\n",
    "num_images = all_classes.shape[0]\n",
    "all_data = [[] for _ in range(11)]\n",
    "for i in tqdm(range(1, num_images), desc=\"Preparing…\",  ascii=False, ncols=75): \n",
    "    all_data[all_classes[i]].append(all_images[i])\n",
    "all_data = [np.array(i) for i in all_data]\n",
    "np.savez_compressed('all_data.npz', all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6UjnErwec-ft",
    "outputId": "8a2ca30d-18c2-4997-f9ac-fff11edb03d8"
   },
   "outputs": [],
   "source": [
    "data = all_data[0]\n",
    "print(data.shape)\n",
    "datagen = DataAugmentation(data[:30])\n",
    "images = datagen.get(n_images=5)\n",
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BOtbA0Iuvmg9",
    "outputId": "d9259a7f-e8f8-4704-e34b-3157344c3fe4"
   },
   "outputs": [],
   "source": [
    "import shutil, os\n",
    "\n",
    "try:\n",
    "  augmented_folder = 'augmented'\n",
    "  augmented_subfolder = os.path.join(augmented_folder,'{}')\n",
    "  shutil.rmtree(augmented_folder)\n",
    "  os.mkdir(augmented_folder)\n",
    "  for i in range(11):\n",
    "    print(augmented_subfolder.format(i))\n",
    "    os.mkdir(augmented_subfolder.format(i))\n",
    "except:\n",
    "    pass\n",
    "    \n",
    "i = 0\n",
    "for batch in datagen.flow(data, batch_size=1, save_to_dir=augmented_subfolder.format(0), save_prefix='', save_format='jpeg'):\n",
    "    i += 1\n",
    "    if i > 20:\n",
    "        break  # otherwise the generator would loop indefinitely\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fRDYLERI4RXa",
    "outputId": "b3cf742b-a951-406f-fd4b-4675ad0516d1"
   },
   "outputs": [],
   "source": [
    "len([name for name in os.listdir(augmented_subfolder.format(0))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SaPIIX3rQSWi"
   },
   "source": [
    "# Part V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4xeLm-8yQWAH",
    "outputId": "b3a24b29-6ccf-447a-ff69-e91c2a7c6acf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vu15B290ZX2K"
   },
   "source": [
    "## Part VI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P4CEAu1BZc7u"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import data\n",
    "from skimage.transform import pyramid_gaussian\n",
    "from transform import resize_image\n",
    "\n",
    "from prepare_data import get_number_of_files, load_negative, load_positive, prepare_data, getGroundTruthList\n",
    "num_scales = 4\n",
    "image = load_positive(17)\n",
    "print(image.shape)\n",
    "target_size = (224,224)\n",
    "scale= min(target_size)/min(image.shape[:-1]) *1.25* 2**(num_scales-1)\n",
    "image = resize_image(image, target_size= (int(image.shape[1]*scale),int(image.shape[0]*scale)))\n",
    "print(image.shape)\n",
    "\n",
    "pyramid = tuple(pyramid_gaussian(image, max_layer=num_scales-1, downscale=2, multichannel=True))\n",
    "\n",
    "fig, ax = plt.subplots(1, num_scales, gridspec_kw={'width_ratios': [2**i for i in range(num_scales-1,-1,-1)]})\n",
    "for i in range(num_scales):\n",
    "    ax[i].imshow(pyramid[i])\n",
    "fig.set_size_inches(20,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JHglgUII0Gfv"
   },
   "outputs": [],
   "source": [
    "overlap = 0.2\n",
    "def get_image_slides(image,overlap=0.2,target_size=target_size):\n",
    "    def calculate_number(tar_size,im_size,overlap):\n",
    "      return int((im_size/tar_size-1)/(1-overlap))\n",
    "    ncol = calculate_number(target_size[1],image.shape[1],overlap)\n",
    "    nrow = calculate_number(target_size[0],image.shape[0],overlap)\n",
    "    images = []\n",
    "    for col in range(ncol):\n",
    "      for row in range(nrow):\n",
    "        c_start = col*int(target_size[1]*(1-overlap))\n",
    "        c_end = c_start + target_size[1]    \n",
    "        r_start = row*int(target_size[0]*(1-overlap))\n",
    "        r_end = r_start + target_size[0]\n",
    "        # print(r_start,r_end,c_start,c_end)\n",
    "        img = image[r_start:r_end,c_start:c_end,:]\n",
    "        images.append(img)\n",
    "    images = np.array(images)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bfvx9_hrCe9t"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "model = tf.keras.models.load_model('pre_train.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YLyytMeB4X6D"
   },
   "outputs": [],
   "source": [
    "images = get_image_slides(pyramid[0],overlap=0.75,target_size=target_size).astype(np.float) / 255.\n",
    "# images = x_test;\n",
    "yhat = model.predict(images)\n",
    "######\n",
    "# def estimate(images, thresh=0.2):\n",
    "#   yhat > thresh\n",
    "# index = []\n",
    "# for i in range(yhat.shape[0]):\n",
    "#   ind = np.where(yhat[i]>0.)[0]\n",
    "#   ind_max = yhat[i][ind].argmax()\n",
    "#   print(ind_max)\n",
    "#   ind_max = ind_max if ind_max.shape else 0\n",
    "#   index.append(ind_max)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "HW04_Q2.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
